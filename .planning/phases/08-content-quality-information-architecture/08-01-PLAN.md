---
phase: 08-content-quality-information-architecture
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/08-content-quality-information-architecture/inventory/content-inventory.csv
  - .planning/phases/08-content-quality-information-architecture/inventory/grammar-report.txt
  - .planning/phases/08-content-quality-information-architecture/inventory/duplicate-report.txt
  - .planning/phases/08-content-quality-information-architecture/inventory/ia-analysis.md
  - .planning/phases/08-content-quality-information-architecture/scripts/extract-content.mjs
  - .planning/phases/08-content-quality-information-architecture/scripts/check-grammar.mjs
  - .planning/phases/08-content-quality-information-architecture/scripts/find-duplicates.mjs
  - package.json
autonomous: true
requirements:
  - CONTENT-01
  - CONTENT-03

must_haves:
  truths:
    - "Content inventory CSV exists with every section from all 16 public pages cataloged"
    - "Grammar report identifies prose issues across all 16 pages using write-good"
    - "Duplicate content report identifies repeated text blocks across pages"
    - "IA analysis document assesses each page's purpose, audience fit, and content placement"
  artifacts:
    - path: ".planning/phases/08-content-quality-information-architecture/inventory/content-inventory.csv"
      provides: "Section-level inventory of all 16 public pages"
      contains: "page,section"
    - path: ".planning/phases/08-content-quality-information-architecture/inventory/grammar-report.txt"
      provides: "Automated grammar and prose quality findings"
    - path: ".planning/phases/08-content-quality-information-architecture/inventory/duplicate-report.txt"
      provides: "Cross-page content duplication analysis"
    - path: ".planning/phases/08-content-quality-information-architecture/inventory/ia-analysis.md"
      provides: "Information architecture assessment with page roles and recommendations"
    - path: ".planning/phases/08-content-quality-information-architecture/scripts/extract-content.mjs"
      provides: "HTML text extraction for analysis"
    - path: ".planning/phases/08-content-quality-information-architecture/scripts/check-grammar.mjs"
      provides: "Prose quality linter using write-good"
    - path: ".planning/phases/08-content-quality-information-architecture/scripts/find-duplicates.mjs"
      provides: "Cross-page duplicate content detector"
  key_links:
    - from: "scripts/extract-content.mjs"
      to: "inventory/content-inventory.csv"
      via: "Script generates CSV from HTML pages"
      pattern: "writeFileSync.*content-inventory"
    - from: "scripts/check-grammar.mjs"
      to: "inventory/grammar-report.txt"
      via: "Script outputs prose issues to report"
      pattern: "writeGood"
---

<objective>
Build content analysis infrastructure and generate comprehensive inventory data for all 16 public pages. This plan produces the decision-support artifacts that drive all subsequent editorial work in Plans 02-04.

Purpose: Cannot make informed editorial decisions (ROT audit, IA optimization, grammar fixes) without first understanding what content exists, where it lives, and what automated tools flag. This is the "measure twice" before "cut once."

Output: Content inventory CSV, grammar report, duplicate report, IA analysis document, and reusable analysis scripts.
</objective>

<execution_context>
@/home/xhiris/.claude/get-shit-done/workflows/execute-plan.md
@/home/xhiris/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-content-quality-information-architecture/08-CONTEXT.md
@.planning/phases/08-content-quality-information-architecture/08-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create content extraction and analysis scripts</name>
  <files>
    .planning/phases/08-content-quality-information-architecture/scripts/extract-content.mjs
    .planning/phases/08-content-quality-information-architecture/scripts/check-grammar.mjs
    .planning/phases/08-content-quality-information-architecture/scripts/find-duplicates.mjs
    package.json
  </files>
  <action>
    Install dependencies: `npm install --save-dev write-good cheerio glob`

    Create three analysis scripts in `.planning/phases/08-content-quality-information-architecture/scripts/`:

    **extract-content.mjs:**
    - Use cheerio to parse all 16 public HTML files (exclude review.html)
    - Pages: index.html, philosophy.html, portfolio.html, technologies.html, faq.html, contact.html, testimonials.html, plus all 12 exhibits in exhibits/ directory (exhibit-a through exhibit-l, no exhibit-e)
    - Extract section-level data: page path, section index, heading text (h1/h2/h3), word count, first 100 chars preview
    - Remove script, style, nav, footer elements before extraction
    - Output CSV with columns: page, section_index, heading, word_count, preview
    - Write to `inventory/content-inventory.csv`

    **check-grammar.mjs:**
    - Use cheerio + write-good to lint prose on all 16 public pages
    - Extract main content text (remove nav, footer, script, style)
    - Run write-good on extracted text
    - For each suggestion: show page, approximate position, reason, surrounding context snippet
    - Write output to both stdout and `inventory/grammar-report.txt`
    - NOTE: write-good suggestions are candidates for review, NOT auto-fix targets. Passive voice and adverbs are sometimes correct.

    **find-duplicates.mjs:**
    - Use cheerio to extract paragraph-level text blocks (p, li, h2, h3) from all 16 pages
    - Ignore blocks shorter than 50 characters
    - Find exact-match duplicates appearing on multiple pages
    - Also find near-duplicates: normalize text (lowercase, collapse whitespace, strip punctuation) and compare
    - Report: text block, all pages it appears on, whether exact or near match
    - Write to `inventory/duplicate-report.txt`

    Add npm scripts to package.json:
    ```json
    "scripts": {
      "audit:inventory": "node .planning/phases/08-content-quality-information-architecture/scripts/extract-content.mjs",
      "audit:grammar": "node .planning/phases/08-content-quality-information-architecture/scripts/check-grammar.mjs",
      "audit:duplicates": "node .planning/phases/08-content-quality-information-architecture/scripts/find-duplicates.mjs",
      "audit:all": "npm run audit:inventory && npm run audit:grammar && npm run audit:duplicates"
    }
    ```

    Ensure scripts use proper ESM imports and handle the file paths relative to project root (scripts run from project root via npm).
  </action>
  <verify>
    Run each script successfully:
    ```bash
    npm run audit:inventory   # Should create content-inventory.csv
    npm run audit:grammar     # Should create grammar-report.txt
    npm run audit:duplicates  # Should create duplicate-report.txt
    ```
    Verify inventory CSV has rows for all 16 pages. Verify grammar report covers all pages. Verify duplicate report runs without errors.
  </verify>
  <done>
    Three working analysis scripts installed and runnable via npm scripts. Content inventory CSV generated with section-level data for all 16 public pages. Grammar report generated. Duplicate report generated.
  </done>
</task>

<task type="auto">
  <name>Task 2: Generate IA analysis from inventory data</name>
  <files>
    .planning/phases/08-content-quality-information-architecture/inventory/ia-analysis.md
  </files>
  <action>
    Read the generated content-inventory.csv, grammar-report.txt, and duplicate-report.txt. Also read every public HTML page to understand actual content (not just extracted text).

    Create a comprehensive IA analysis document at `inventory/ia-analysis.md` with these sections:

    **1. Page Roles Assessment**
    For each of the 16 pages, define:
    - Current role (what the page does now)
    - Ideal role per user decisions from CONTEXT.md:
      - index.html: hook + route, quick credibility, funnel to depth
      - philosophy.html: core page, culture fit filter, methodology/values
      - portfolio.html: NTSB "probable cause summaries"
      - technologies.html: determine purpose (skills inventory vs breadth showcase)
      - faq.html: assess - strengthen, merge, or retire
      - contact.html: action page, "not a good fit" criteria, engagement types
      - testimonials.html: social proof, field reports
      - exhibits: NTSB "full investigation reports"
    - Gap between current and ideal
    - Recommended action (keep as-is, trim, restructure, merge, retire)

    **2. Audience Journey Mapping**
    For each audience (hiring managers 30s, engineers 3-4min, clients full review):
    - Likely entry points
    - Expected navigation path
    - What content they need to see and where
    - Current gaps or friction points

    **3. Redundancy Map**
    Using duplicate report + manual review:
    - List all content that appears in multiple locations
    - For each: recommend canonical location and whether echoes should stay
    - Per user decision: use judgment case-by-case on consolidate vs allow echoes

    **4. Content Placement Issues**
    - Content that's on the wrong page (per IA evaluation heuristics from research)
    - Deep technical details on index.html (move to exhibit)
    - Generic language on philosophy.html (strengthen or remove)
    - Technology lists without context

    **5. Exhibit Assessment**
    For each of the 12 exhibits:
    - Current structure summary
    - How well it fits NTSB investigation model
    - Recommended structure variant (standard Challenge/Approach/Solution/Results OR investigation-inspired Situation/Investigation/Analysis/Findings/Impact)
    - Recommended depth (more/less space based on story strength)
    - Any consolidation candidates

    **6. Recommended Exhibit Ordering**
    For portfolio page: recommend exhibit display order based on story strength and impact.

    **7. FAQ Assessment**
    Specific recommendation: strengthen in place, merge content into other pages, or retire entirely.

    **8. Navigation Recommendations**
    - Recommended nav structure based on page roles
    - Suggested first-time visitor path
    - CTAs per page (subtle nudges vs navigation-only)

    **9. Proprietary Content Flags**
    Flag anything that might reveal proprietary details about former employer (GP) or client proprietary information, per user decision to exercise caution.

    This document becomes the editorial blueprint for Plans 02-04.
  </action>
  <verify>
    Verify ia-analysis.md exists and contains all 9 sections. Verify every public page is mentioned in the page roles assessment. Verify all 12 exhibits are individually assessed. Verify the document provides actionable recommendations (not just observations).
  </verify>
  <done>
    Comprehensive IA analysis document exists with page role assessments for all 16 pages, audience journey maps for 3 audiences, redundancy map, content placement issues, individual exhibit assessments with structure recommendations, exhibit ordering recommendation, FAQ fate recommendation, navigation recommendations, and proprietary content flags.
  </done>
</task>

</tasks>

<verification>
1. `npm run audit:all` completes without errors
2. content-inventory.csv has rows covering all 16 public pages (zero pages missing)
3. grammar-report.txt contains findings (may have zero issues on some pages, but script ran on all)
4. duplicate-report.txt shows analysis results
5. ia-analysis.md is comprehensive with all 9 required sections
6. ia-analysis.md references specific pages and sections (not generic advice)
7. All 12 exhibits individually assessed in ia-analysis.md
</verification>

<success_criteria>
- Content inventory CSV generated with section-level data for all 16 public pages
- Grammar/prose quality report generated for all 16 pages
- Duplicate content report generated showing cross-page repetition
- IA analysis document provides actionable editorial blueprint for Plans 02-04
- Scripts are reusable (can be re-run after edits to verify improvements)
</success_criteria>

<output>
After completion, create `.planning/phases/08-content-quality-information-architecture/08-01-SUMMARY.md`
</output>
